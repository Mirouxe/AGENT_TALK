// √âtat de l'application
let mediaRecorder;
let audioChunks = [];
let isRecording = false;
let recordingStartTime;
let timerInterval;

// √âl√©ments du DOM
const recordBtn = document.getElementById('record-btn');
const statusText = document.getElementById('status-text');
const statusIndicator = document.getElementById('status-indicator');
const recordingInfo = document.getElementById('recording-info');
const timerElement = document.getElementById('timer');
const audioPlayback = document.getElementById('audio-playback');
const processCard = document.getElementById('process-card');
const resultCard = document.getElementById('result-card');
const errorCard = document.getElementById('error-card');

/**
 * Basculer entre d√©marrer et arr√™ter l'enregistrement
 */
async function toggleRecording() {
    if (!isRecording) {
        await startRecording();
    } else {
        stopRecording();
    }
}

/**
 * D√©marrer l'enregistrement audio
 */
async function startRecording() {
    try {
        // Demander l'acc√®s au microphone
        const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
        
        // Cr√©er le MediaRecorder
        mediaRecorder = new MediaRecorder(stream);
        audioChunks = [];
        
        // Collecter les donn√©es audio
        mediaRecorder.addEventListener('dataavailable', event => {
            audioChunks.push(event.data);
        });
        
        // Traiter l'audio quand l'enregistrement s'arr√™te
        mediaRecorder.addEventListener('stop', handleRecordingComplete);
        
        // D√©marrer l'enregistrement
        mediaRecorder.start();
        isRecording = true;
        recordingStartTime = Date.now();
        
        // Mettre √† jour l'interface
        updateUIForRecording();
        
        // D√©marrer le timer
        startTimer();
        
    } catch (error) {
        console.error('Erreur lors du d√©marrage de l\'enregistrement:', error);
        showError('Impossible d\'acc√©der au microphone. Veuillez autoriser l\'acc√®s.');
    }
}

/**
 * Arr√™ter l'enregistrement audio
 */
function stopRecording() {
    if (mediaRecorder && isRecording) {
        mediaRecorder.stop();
        isRecording = false;
        
        // Arr√™ter le timer
        clearInterval(timerInterval);
        
        // Arr√™ter le stream
        mediaRecorder.stream.getTracks().forEach(track => track.stop());
        
        // Mettre √† jour l'interface
        updateUIForStopped();
    }
}

/**
 * Traiter l'enregistrement termin√©
 */
async function handleRecordingComplete() {
    // Cr√©er un blob audio
    const audioBlob = new Blob(audioChunks, { type: 'audio/webm' });
    
    // Cr√©er une URL pour la lecture
    const audioUrl = URL.createObjectURL(audioBlob);
    audioPlayback.src = audioUrl;
    audioPlayback.style.display = 'block';
    
    // Envoyer l'audio au serveur pour traitement
    await processAudio(audioBlob);
}

/**
 * Envoyer l'audio au serveur pour traitement
 */
async function processAudio(audioBlob) {
    // Afficher la carte de traitement
    processCard.style.display = 'block';
    resultCard.style.display = 'none';
    errorCard.style.display = 'none';
    
    try {
        // Cr√©er un FormData
        const formData = new FormData();
        formData.append('audio', audioBlob, 'recording.webm');
        
        // Mettre √† jour l'interface - Transcription
        updateStepStatus('step-transcription', 'active', 'En cours...');
        
        // Envoyer au serveur
        const response = await fetch('/api/process-audio', {
            method: 'POST',
            body: formData
        });
        
        if (!response.ok) {
            throw new Error('Erreur lors du traitement de l\'audio');
        }
        
        const result = await response.json();
        
        // Mettre √† jour l'interface - Transcription termin√©e
        updateStepStatus('step-transcription', 'completed', 'Termin√© ‚úì');
        
        // Nettoyage
        updateStepStatus('step-cleaning', 'active', 'En cours...');
        
        // Simuler un d√©lai pour l'affichage
        await new Promise(resolve => setTimeout(resolve, 500));
        updateStepStatus('step-cleaning', 'completed', 'Termin√© ‚úì');
        
        // Notion
        updateStepStatus('step-notion', 'active', 'En cours...');
        await new Promise(resolve => setTimeout(resolve, 500));
        updateStepStatus('step-notion', 'completed', 'Termin√© ‚úì');
        
        // Afficher les r√©sultats
        showResults(result);
        
    } catch (error) {
        console.error('Erreur lors du traitement:', error);
        showError(error.message || 'Une erreur est survenue lors du traitement de votre enregistrement.');
    }
}

/**
 * Mettre √† jour le statut d'une √©tape
 */
function updateStepStatus(stepId, status, text) {
    const step = document.getElementById(stepId);
    const statusElement = step.querySelector('.step-status');
    
    step.className = 'step ' + status;
    statusElement.textContent = text;
}

/**
 * Afficher les r√©sultats
 */
function showResults(result) {
    processCard.style.display = 'none';
    resultCard.style.display = 'block';
    
    document.getElementById('transcription-text').textContent = result.transcription;
    document.getElementById('cleaned-text').textContent = result.cleaned_text;
    document.getElementById('notion-link').href = result.notion_url;
}

/**
 * Afficher une erreur
 */
function showError(message) {
    processCard.style.display = 'none';
    resultCard.style.display = 'none';
    errorCard.style.display = 'block';
    document.getElementById('error-message').textContent = message;
}

/**
 * R√©initialiser l'application
 */
function resetApp() {
    processCard.style.display = 'none';
    resultCard.style.display = 'none';
    errorCard.style.display = 'none';
    audioPlayback.style.display = 'none';
    recordingInfo.style.display = 'none';
    
    // R√©initialiser les √©tapes
    ['step-transcription', 'step-cleaning', 'step-notion'].forEach(stepId => {
        updateStepStatus(stepId, '', 'En attente...');
    });
    
    // R√©initialiser l'interface d'enregistrement
    recordBtn.innerHTML = '<span class="btn-icon">üé§</span><span class="btn-text">Commencer l\'enregistrement</span>';
    recordBtn.className = 'btn btn-record';
    statusText.textContent = 'Pr√™t √† enregistrer';
    statusIndicator.className = 'status-indicator';
}

/**
 * D√©marrer le timer
 */
function startTimer() {
    timerInterval = setInterval(() => {
        const elapsed = Date.now() - recordingStartTime;
        const minutes = Math.floor(elapsed / 60000);
        const seconds = Math.floor((elapsed % 60000) / 1000);
        timerElement.textContent = `${String(minutes).padStart(2, '0')}:${String(seconds).padStart(2, '0')}`;
    }, 1000);
}

/**
 * Mettre √† jour l'interface pour l'enregistrement
 */
function updateUIForRecording() {
    recordBtn.innerHTML = '<span class="btn-icon">‚èπ</span><span class="btn-text">Arr√™ter l\'enregistrement</span>';
    recordBtn.className = 'btn btn-record recording';
    statusText.textContent = 'Enregistrement en cours...';
    statusIndicator.className = 'status-indicator recording';
    recordingInfo.style.display = 'flex';
    audioPlayback.style.display = 'none';
}

/**
 * Mettre √† jour l'interface pour l'arr√™t
 */
function updateUIForStopped() {
    recordBtn.innerHTML = '<span class="btn-icon">üé§</span><span class="btn-text">Nouvel enregistrement</span>';
    recordBtn.className = 'btn btn-record';
    statusText.textContent = 'Traitement en cours...';
    statusIndicator.className = 'status-indicator';
    recordingInfo.style.display = 'none';
}

// V√©rifier que le navigateur supporte l'API MediaRecorder
if (!navigator.mediaDevices || !navigator.mediaDevices.getUserMedia) {
    showError('Votre navigateur ne supporte pas l\'enregistrement audio. Veuillez utiliser un navigateur moderne.');
}

